{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "600d5914",
   "metadata": {},
   "source": [
    "# Normalization Process Documentation\n",
    "\n",
    "This notebook normalizes the mining data collected in the `logs` directory:\n",
    "\n",
    "1. **For Screenshots**:\n",
    "   - Resizes images to max 1120x1120 pixels while preserving aspect ratio\n",
    "   - Keeps original filenames\n",
    "   \n",
    "2. **For JSON Files**:\n",
    "   - Normalizes click coordinates to 0-1 range (if not already normalized)\n",
    "   - Normalizes by dividing x by screen width and y by screen height\n",
    "   - Preserves all other data\n",
    "   \n",
    "3. **Output Structure**:\n",
    "   - Saves to a specific folder in `../data/normalized/[hostname]_[timestamp]/`\n",
    "   - Maintains the same folder structure as the original logs directory\n",
    "   - Copies session_prompts.log if it exists\n",
    "\n",
    "## How to Use\n",
    "\n",
    "1. Run all cells in order\n",
    "2. The normalized data will be saved to a new directory in `../data/normalized/`\n",
    "3. Each normalization run creates a subfolder named `[hostname]_[timestamp]`\n",
    "\n",
    "You can now use this normalized data with your analysis or training scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4270f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "import shutil\n",
    "import socket\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import pyautogui\n",
    "from tqdm import tqdm  # Changed from tqdm.notebook to avoid ipywidgets dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a982a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "# Get screen width and height for reference\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "print(f\"Screen size: {screen_width}x{screen_height}\")\n",
    "\n",
    "# Define paths\n",
    "ROOT_DIR = os.path.abspath('../')\n",
    "MINING_DIR = os.path.join(ROOT_DIR, 'mining')\n",
    "# LOGS_DIR = os.path.join(MINING_DIR, 'logs')\n",
    "LOGS_DIR = os.path.join(ROOT_DIR, 'data', 'old 5-1-2025')\n",
    "SCREENSHOTS_DIR = os.path.join(LOGS_DIR, 'screenshots')\n",
    "JSON_DIR = os.path.join(LOGS_DIR, 'sanitized_json')\n",
    "\n",
    "# Generate distinctive subfolder name with timestamp and hostname\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "hostname = socket.gethostname().replace(\".\", \"_\")\n",
    "NORMALIZED_SUBFOLDER = f\"{hostname}_{timestamp}\"\n",
    "\n",
    "# Set up output directory structure\n",
    "OUTPUT_DIR = os.path.join(ROOT_DIR, 'data', 'normalized', NORMALIZED_SUBFOLDER)\n",
    "OUTPUT_SCREENSHOTS_DIR = os.path.join(OUTPUT_DIR, 'screenshots')\n",
    "OUTPUT_JSON_DIR = os.path.join(OUTPUT_DIR, 'sanitized_json')\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_SCREENSHOTS_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_JSON_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Mining directory: {MINING_DIR}\")\n",
    "print(f\"Input screenshots: {SCREENSHOTS_DIR}\")\n",
    "print(f\"Input JSON: {JSON_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Output screenshots: {OUTPUT_SCREENSHOTS_DIR}\")\n",
    "print(f\"Output JSON: {OUTPUT_JSON_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dff87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize image size\n",
    "def normalize_image_size(img, max_size=(1120, 1120)):\n",
    "    \"\"\"Resize an image to a maximum size while preserving aspect ratio.\"\"\"\n",
    "    original_width, original_height = img.size\n",
    "\n",
    "    # Calculate width and height ratios\n",
    "    width_ratio = max_size[0] / original_width\n",
    "    height_ratio = max_size[1] / original_height\n",
    "\n",
    "    # Use the smaller ratio to ensure both dimensions fit within max_size\n",
    "    resize_ratio = min(width_ratio, height_ratio)\n",
    "\n",
    "    # Only resize if the image is larger than max_size\n",
    "    if resize_ratio < 1:\n",
    "        new_width = int(original_width * resize_ratio)\n",
    "        new_height = int(original_height * resize_ratio)\n",
    "        return img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "# Process all screenshot images\n",
    "def process_screenshots():\n",
    "    \"\"\"Process and normalize all screenshot images.\"\"\"\n",
    "\n",
    "    # Get all screenshot files\n",
    "    screenshot_files = glob.glob(os.path.join(SCREENSHOTS_DIR, \"*.jpg\"))\n",
    "    print(f\"Found {len(screenshot_files)} screenshots to process\")\n",
    "\n",
    "    # Process each screenshot\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "    for filepath in tqdm(screenshot_files, desc=\"Normalizing screenshots\"):\n",
    "        try:\n",
    "            # Get the filename\n",
    "            filename = os.path.basename(filepath)\n",
    "            output_path = os.path.join(OUTPUT_SCREENSHOTS_DIR, filename)\n",
    "\n",
    "            # Load and normalize the image\n",
    "            img = Image.open(filepath)\n",
    "            normalized_img = normalize_image_size(img)\n",
    "\n",
    "            # Save with the same filename\n",
    "            normalized_img.save(output_path, quality=95)\n",
    "            success_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {e}\")\n",
    "            error_count += 1\n",
    "\n",
    "    print(f\"Screenshot processing complete: {success_count} successful, {error_count} errors\")\n",
    "    return success_count, error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed58d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process JSON files\n",
    "def process_json_files():\n",
    "    \"\"\"Process all JSON files, normalizing coordinates to 0-1 range if needed.\"\"\"\n",
    "\n",
    "    # Get all JSON files\n",
    "    json_files = glob.glob(os.path.join(JSON_DIR, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to process\")\n",
    "\n",
    "    # Initialize statistics\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "    files_with_nonnormalized_coords = 0\n",
    "    events_normalized = 0\n",
    "\n",
    "    for filepath in tqdm(json_files, desc=\"Processing JSON files\"):\n",
    "        try:\n",
    "            # Get the filename\n",
    "            filename = os.path.basename(filepath)\n",
    "            output_path = os.path.join(OUTPUT_JSON_DIR, filename)\n",
    "\n",
    "            # Load JSON data\n",
    "            with open(filepath, 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Track if this file needed normalization\n",
    "            file_needed_normalization = False\n",
    "\n",
    "            # Check coordinates in events\n",
    "            for event in data.get('events', []):\n",
    "                if event.get('event') == 'MOUSE':\n",
    "                    # Check x coordinate\n",
    "                    if 'x' in event:\n",
    "                        x = event['x']\n",
    "                        # If x is an integer or > 1, it's likely not normalized\n",
    "                        if isinstance(x, int) or x > 1:\n",
    "                            file_needed_normalization = True\n",
    "                            events_normalized += 1\n",
    "                            # Normalize by dividing by screen width\n",
    "                            event['x'] = x / screen_width\n",
    "\n",
    "                    # Check y coordinate\n",
    "                    if 'y' in event:\n",
    "                        y = event['y']\n",
    "                        # If y is an integer or > 1, it's likely not normalized\n",
    "                        if isinstance(y, int) or y > 1:\n",
    "                            file_needed_normalization = True\n",
    "                            # Normalize by dividing by screen height\n",
    "                            event['y'] = y / screen_height\n",
    "\n",
    "            # Save JSON file\n",
    "            with open(output_path, 'w') as f:\n",
    "                json.dump(data, f, indent=2)\n",
    "\n",
    "            if file_needed_normalization:\n",
    "                files_with_nonnormalized_coords += 1\n",
    "\n",
    "            success_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {e}\")\n",
    "            error_count += 1\n",
    "\n",
    "    print(f\"JSON processing complete: {success_count} successful, {error_count} errors\")\n",
    "    print(f\"Files with non-normalized coordinates: {files_with_nonnormalized_coords}\")\n",
    "    print(f\"Total events normalized: {events_normalized}\")\n",
    "    return success_count, error_count, files_with_nonnormalized_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feccf31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the normalization process\n",
    "\n",
    "# Process screenshots\n",
    "screenshot_results = process_screenshots()\n",
    "\n",
    "# Process JSON files\n",
    "json_results = process_json_files()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n===== Normalization Summary =====\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Screenshots normalized: {screenshot_results[0]}\")\n",
    "print(f\"JSON files processed: {json_results[0]}\")\n",
    "print(f\"Files with coordinates normalized: {json_results[2]}\")\n",
    "\n",
    "# Copy session_prompts.log if it exists\n",
    "session_prompts_path = os.path.join(LOGS_DIR, \"session_prompts.log\")\n",
    "if os.path.exists(session_prompts_path):\n",
    "    output_session_prompts = os.path.join(OUTPUT_DIR, \"session_prompts.log\")\n",
    "    shutil.copy2(session_prompts_path, output_session_prompts)\n",
    "    print(f\"Copied session_prompts.log to output directory\")\n",
    "\n",
    "print(\"\\nNormalization complete! The normalized data is ready for use.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
