{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e424d0cf-8719-423a-bb2e-41cf72573c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.9\n",
      "total 148\n",
      "drwxr-xr-x 5 1989098223 1954200513  4608 Nov 12 21:48 .\n",
      "drwxr-xr-x 7 1989098223 1954200513  6144 Nov 12 00:26 ..\n",
      "-rw-r--r-- 1 1989098223 1954200513 31179 Nov 11 23:35 cellCode.ipynb\n",
      "-rw-r--r-- 1 1989098223 1954200513 23576 Nov 12 21:48 generate_dataset.ipynb\n",
      "drwxr-xr-x 2 1989098223 1954200513  2560 Nov 12 20:04 .ipynb_checkpoints\n",
      "-rw-r--r-- 1 1989098223 1954200513  8042 Nov 11 22:34 llama_3.2_lora.py\n",
      "drwxr-xr-x 9 1989098223 1954200513  7680 Nov  4 17:12 llama-recipes\n",
      "-rw-r--r-- 1 1989098223 1954200513  4583 Nov 12 13:32 ocrvqa_dataset.py\n",
      "drwxr-xr-x 2 1989098223 1954200513  1024 Nov 12 13:53 __pycache__\n",
      "-rw-r--r-- 1 1989098223 1954200513 21004 Nov 12 21:14 torch_run.ipynb\n",
      "-rw-r--r-- 1 1989098223 1954200513  4444 Nov 12 21:12 web_scraper_dataset.py\n",
      "Sat Nov 16 15:46:59 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off |   00000000:02:00.0 Off |                    0 |\n",
      "| N/A   55C    P0             92W /  300W |    3631MiB /  81920MiB |     37%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          Off |   00000000:64:00.0 Off |                    0 |\n",
      "| N/A   33C    P0             43W /  300W |       3MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          Off |   00000000:82:00.0 Off |                    0 |\n",
      "| N/A   35C    P0             45W /  300W |       3MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA A100 80GB PCIe          Off |   00000000:E3:00.0 Off |                    0 |\n",
      "| N/A   34C    P0             41W /  300W |       3MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   3039429      C   python                                       3622MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "/bin/bash: line 0: cd: training: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python3 --version\n",
    "!ls -al\n",
    "!nvidia-smi\n",
    "!cd training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e88685-47cb-4a35-a589-0d6a7cbc28bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1116 20:49:22.579000 3113762 torch/distributed/run.py:793] \n",
      "W1116 20:49:22.579000 3113762 torch/distributed/run.py:793] *****************************************\n",
      "W1116 20:49:22.579000 3113762 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W1116 20:49:22.579000 3113762 torch/distributed/run.py:793] *****************************************\n",
      "FINETUNING LOCAL\n",
      "FINETUNING LOCAL\n",
      "FINETUNING LOCAL\n",
      "FINETUNING LOCAL\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/llama_recipes/model_checkpointing/checkpoint_handler.py:17: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead\n",
      "  from torch.distributed._shard.checkpoint import (\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/llama_recipes/model_checkpointing/checkpoint_handler.py:17: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead\n",
      "  from torch.distributed._shard.checkpoint import (\n",
      "{'batch_size_training': 8,\n",
      " 'batching_strategy': 'padding',\n",
      " 'custom_dataset.file': 'web_scraper_dataset.py',\n",
      " 'custom_dataset.test_split': 'test',\n",
      " 'dataset': 'custom_dataset',\n",
      " 'dist_checkpoint_folder': 'fine-tuned',\n",
      " 'dist_checkpoint_root_folder': './finetuned_model',\n",
      " 'enable_fsdp': True,\n",
      " 'lr': 1e-05,\n",
      " 'model_name': 'meta-llama/Llama-3.2-11B-Vision-Instruct',\n",
      " 'num_epochs': 3,\n",
      " 'peft_method': 'lora',\n",
      " 'run_validation': True,\n",
      " 'use_fast_kernels': True,\n",
      " 'use_peft': True}\n",
      "{'batch_size_training': 8,\n",
      " 'batching_strategy': 'padding',\n",
      " 'custom_dataset.file': 'web_scraper_dataset.py',\n",
      " 'custom_dataset.test_split': 'test',\n",
      " 'dataset': 'custom_dataset',\n",
      " 'dist_checkpoint_folder': 'fine-tuned',\n",
      " 'dist_checkpoint_root_folder': './finetuned_model',\n",
      " 'enable_fsdp': True,\n",
      " 'lr': 1e-05,\n",
      " 'model_name': 'meta-llama/Llama-3.2-11B-Vision-Instruct',\n",
      " 'num_epochs': 3,\n",
      " 'peft_method': 'lora',\n",
      " 'run_validation': True,\n",
      " 'use_fast_kernels': True,\n",
      " 'use_peft': True}\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/llama_recipes/model_checkpointing/checkpoint_handler.py:17: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead\n",
      "  from torch.distributed._shard.checkpoint import (\n",
      "{'batch_size_training': 8,\n",
      " 'batching_strategy': 'padding',\n",
      " 'custom_dataset.file': 'web_scraper_dataset.py',\n",
      " 'custom_dataset.test_split': 'test',\n",
      " 'dataset': 'custom_dataset',\n",
      " 'dist_checkpoint_folder': 'fine-tuned',\n",
      " 'dist_checkpoint_root_folder': './finetuned_model',\n",
      " 'enable_fsdp': True,\n",
      " 'lr': 1e-05,\n",
      " 'model_name': 'meta-llama/Llama-3.2-11B-Vision-Instruct',\n",
      " 'num_epochs': 3,\n",
      " 'peft_method': 'lora',\n",
      " 'run_validation': True,\n",
      " 'use_fast_kernels': True,\n",
      " 'use_peft': True}\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/llama_recipes/model_checkpointing/checkpoint_handler.py:17: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead\n",
      "  from torch.distributed._shard.checkpoint import (\n",
      "{'batch_size_training': 8,\n",
      " 'batching_strategy': 'padding',\n",
      " 'custom_dataset.file': 'web_scraper_dataset.py',\n",
      " 'custom_dataset.test_split': 'test',\n",
      " 'dataset': 'custom_dataset',\n",
      " 'dist_checkpoint_folder': 'fine-tuned',\n",
      " 'dist_checkpoint_root_folder': './finetuned_model',\n",
      " 'enable_fsdp': True,\n",
      " 'lr': 1e-05,\n",
      " 'model_name': 'meta-llama/Llama-3.2-11B-Vision-Instruct',\n",
      " 'num_epochs': 3,\n",
      " 'peft_method': 'lora',\n",
      " 'run_validation': True,\n",
      " 'use_fast_kernels': True,\n",
      " 'use_peft': True}\n",
      "Clearing GPU cache for all ranks\n",
      "--> Running with torch dist debug set to detail\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00,  7.37it/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00,  7.05it/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00,  5.38it/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:01<00:00,  4.94it/s]\n",
      "--> Model meta-llama/Llama-3.2-11B-Vision-Instruct\n",
      "\n",
      "--> meta-llama/Llama-3.2-11B-Vision-Instruct has 10670.220835 Million params\n",
      "\n",
      "trainable params: 5,898,240 || all params: 10,676,119,075 || trainable%: 0.0552\n",
      "trainable params: 5,898,240 || all params: 10,676,119,075 || trainable%: 0.0552\n",
      "trainable params: 5,898,240 || all params: 10,676,119,075 || trainable%: 0.0552\n",
      "bFloat16 enabled for mixed precision - using bfSixteen policy\n",
      "trainable params: 5,898,240 || all params: 10,676,119,075 || trainable%: 0.0552\n",
      "--> applying fsdp activation checkpointing...\n",
      "--> applying fsdp activation checkpointing...\n",
      "--> applying fsdp activation checkpointing...\n",
      "--> applying fsdp activation checkpointing...\n",
      "--> Training Set Length = 14343\n",
      "length of dataset_train 14343\n",
      "custom_data_collator is used\n",
      "--> Num of Training Set Batches loaded = 448\n",
      "--> Num of Validation Set Batches loaded = 398\n",
      "--> Num of Validation Set Batches loaded = 398\n",
      "Starting epoch 0/3\n",
      "train_config.max_train_step: 0\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "Training Epoch: 1:   0%|\u001b[34m                                \u001b[0m| 0/448 [00:00<?, ?it/s]\u001b[0mlength of dataset_train 14343\n",
      "custom_data_collator is used\n",
      "--> Num of Training Set Batches loaded = 448\n",
      "--> Num of Validation Set Batches loaded = 398\n",
      "--> Num of Validation Set Batches loaded = 398\n",
      "Starting epoch 0/3\n",
      "train_config.max_train_step: 0\n",
      "length of dataset_train 14343\n",
      "custom_data_collator is used\n",
      "--> Num of Training Set Batches loaded = 448\n",
      "--> Num of Validation Set Batches loaded = 398\n",
      "--> Num of Validation Set Batches loaded = 398\n",
      "Starting epoch 0/3\n",
      "train_config.max_train_step: 0\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "Training Epoch: 1:   0%|\u001b[34m                                \u001b[0m| 0/448 [00:00<?, ?it/s]\u001b[0m/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "Training Epoch: 1:   0%|\u001b[34m                                \u001b[0m| 0/448 [00:00<?, ?it/s]\u001b[0m--> Validation Set Length = 1594\n",
      "length of dataset_train 14343\n",
      "custom_data_collator is used\n",
      "--> Num of Training Set Batches loaded = 448\n",
      "--> Num of Validation Set Batches loaded = 398\n",
      "--> Num of Validation Set Batches loaded = 398\n",
      "Starting epoch 0/3\n",
      "train_config.max_train_step: 0\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "Training Epoch: 1:   0%|\u001b[34m                                \u001b[0m| 0/448 [00:00<?, ?it/s]\u001b[0m/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "Training Epoch: 1/3, step 447/448 completed (loss: 1.387328028678894): 100%|\u001b[34m█\u001b[0m| 4\u001b[0m\n",
      "Training Epoch: 1/3, step 447/448 completed (loss: 1.3308494091033936): 100%|\u001b[34m█\u001b[0m| \u001b[0m\n",
      "Training Epoch: 1/3, step 447/448 completed (loss: 1.3251367807388306): 100%|\u001b[34m█\u001b[0m| \u001b[0m\n",
      "Training Epoch: 1/3, step 447/448 completed (loss: 1.3364888429641724): 100%|\u001b[34m█\u001b[0m| \u001b[0m\n",
      "Max CUDA memory allocated was 20 GB\n",
      "Max CUDA memory reserved was 22 GB\n",
      "Peak active CUDA memory was 20 GB\n",
      "CUDA Malloc retries : 0\n",
      "CPU Total Peak Memory consumed during the train (max): 119 GB\n",
      "evaluating Epoch: 100%|\u001b[32m███████████████████████\u001b[0m| 398/398 [09:15<00:00,  1.40s/it]\u001b[0m\n",
      "evaluating Epoch: 100%|\u001b[32m███████████████████████\u001b[0m| 398/398 [09:15<00:00,  1.40s/it]\u001b[0m\n",
      "evaluating Epoch: 100%|\u001b[32m███████████████████████\u001b[0m| 398/398 [09:15<00:00,  1.40s/it]\u001b[0m\n",
      "evaluating Epoch: 100%|\u001b[32m███████████████████████\u001b[0m| 398/398 [09:15<00:00,  1.40s/it]\u001b[0m\n",
      " eval_ppl=tensor(3.8330, device='cuda:0') eval_epoch_loss=tensor(1.3436, device='cuda:0')\n",
      "we are about to save the PEFT modules\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "PEFT modules are saved in PATH/to/save/PEFT/model directory\n",
      "Starting epoch 1/3Starting epoch 1/3\n",
      "\n",
      "train_config.max_train_step: 0Starting epoch 1/3train_config.max_train_step: 0\n",
      "\n",
      "\n",
      "train_config.max_train_step: 0\n",
      "best eval loss on epoch 1 is 1.343635082244873\n",
      "Epoch 1: train_perplexity=4.6620, train_epoch_loss=1.5394, epoch time 3206.066318716854s\n",
      "Starting epoch 1/3\n",
      "train_config.max_train_step: 0\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "Training Epoch: 2:   0%|\u001b[34m                                \u001b[0m| 0/448 [00:00<?, ?it/s]\u001b[0m/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "Training Epoch: 2:   0%|\u001b[34m                                \u001b[0m| 0/448 [00:00<?, ?it/s]\u001b[0m/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "Training Epoch: 2:   0%|\u001b[34m                                \u001b[0m| 0/448 [00:00<?, ?it/s]\u001b[0m/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "Training Epoch: 2:   0%|\u001b[34m                                \u001b[0m| 0/448 [00:00<?, ?it/s]\u001b[0m/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Training Epoch: 2/3, step 447/448 completed (loss: 1.2947123050689697): 100%|\u001b[34m█\u001b[0m| \u001b[0m\n",
      "Training Epoch: 2/3, step 447/448 completed (loss: 1.2995730638504028): 100%|\u001b[34m█\u001b[0m| \u001b[0m\n",
      "Training Epoch: 2/3, step 447/448 completed (loss: 1.244439959526062): 100%|\u001b[34m█\u001b[0m| 4\u001b[0m\n",
      "Training Epoch: 2/3, step 447/448 completed (loss: 1.2518699169158936): 100%|\u001b[34m█\u001b[0m| \u001b[0m\n",
      "Max CUDA memory allocated was 20 GB\n",
      "Max CUDA memory reserved was 28 GB\n",
      "Peak active CUDA memory was 20 GB\n",
      "CUDA Malloc retries : 0\n",
      "CPU Total Peak Memory consumed during the train (max): 165 GB\n",
      "evaluating Epoch: 100%|\u001b[32m███████████████████████\u001b[0m| 398/398 [09:15<00:00,  1.39s/it]\u001b[0m\n",
      "evaluating Epoch: 100%|\u001b[32m███████████████████████\u001b[0m| 398/398 [09:15<00:00,  1.39s/it]\u001b[0m\n",
      "evaluating Epoch: 100%|\u001b[32m███████████████████████\u001b[0m| 398/398 [09:15<00:00,  1.39s/it]\u001b[0m\n",
      "evaluating Epoch: 100%|\u001b[32m███████████████████████\u001b[0m| 398/398 [09:15<00:00,  1.40s/it]\u001b[0m\n",
      " eval_ppl=tensor(3.5293, device='cuda:0') eval_epoch_loss=tensor(1.2611, device='cuda:0')\n",
      "we are about to save the PEFT modules\n",
      "PEFT modules are saved in PATH/to/save/PEFT/model directory\n",
      "Starting epoch 2/3\n",
      "train_config.max_train_step: 0\n",
      "Starting epoch 2/3\n",
      "train_config.max_train_step: 0\n",
      "Starting epoch 2/3\n",
      "train_config.max_train_step: 0best eval loss on epoch 2 is 1.2610876560211182\n",
      "\n",
      "Epoch 2: train_perplexity=3.6859, train_epoch_loss=1.3045, epoch time 3214.552999308333s\n",
      "Starting epoch 2/3\n",
      "train_config.max_train_step: 0\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "Training Epoch: 3:   0%|\u001b[34m                                \u001b[0m| 0/448 [00:00<?, ?it/s]\u001b[0m/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "Training Epoch: 3:   0%|\u001b[34m                                \u001b[0m| 0/448 [00:00<?, ?it/s]\u001b[0m/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "Training Epoch: 3:   0%|\u001b[34m                                \u001b[0m| 0/448 [00:00<?, ?it/s]\u001b[0m/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/Users/924284072/git-repos/Visual-Data-Mining-AI-Model/venv_visual_data_mining/lib64/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Training Epoch: 3/3, step 96/448 completed (loss: 1.249785304069519):  22%|\u001b[34m▏\u001b[0m| 97\u001b[0m"
     ]
    }
   ],
   "source": [
    "%cd ~/git-repos/Visual-Data-Mining-AI-Model/training \n",
    "\n",
    "#! CUDA_VISIBLE_DEVICES=1 torchrun --nnodes 1 --nproc_per_node 1  llama-recipes/recipes/quickstart/finetuning/finetuning.py --enable_fsdp --lr 1e-5  --num_epochs 3 --batch_size_training 2 --model_name meta-llama/Llama-3.2-11B-Vision-Instruct --dist_checkpoint_root_folder ./finetuned_model --dist_checkpoint_folder fine-tuned  --use_fast_kernels --dataset \"custom_dataset\" --custom_dataset.test_split \"test\" --custom_dataset.file \"web_scraper_dataset.py\"  --run_validation True --batching_strategy padding  --use_peft --peft_method lora\n",
    "#! CUDA_VISIBLE_DEVICES=1 torchrun --nnodes 1 --nproc_per_node 1  llama-recipes/recipes/quickstart/finetuning/finetuning.py --enable_fsdp --lr 1e-5  --num_epochs 3 --batch_size_training 2 --model_name meta-llama/Llama-3.2-11B-Vision-Instruct --dist_checkpoint_root_folder ./finetuned_model --dist_checkpoint_folder fine-tuned  --use_fast_kernels --dataset \"custom_dataset\" --custom_dataset.test_split \"test\" --custom_dataset.file \"ocrvqa_dataset.py\"  --run_validation True --batching_strategy padding  --use_peft --peft_method lora%cd ~/git-repos/Visual-Data-Mining-AI-Model/training \n",
    "\n",
    "!torchrun --nnodes 1 --nproc_per_node 4  finetuning.py --enable_fsdp --lr 1e-5  --num_epochs 3 --batch_size_training 8 --model_name meta-llama/Llama-3.2-11B-Vision-Instruct --dist_checkpoint_root_folder ./finetuned_model --dist_checkpoint_folder fine-tuned  --use_fast_kernels --dataset \"custom_dataset\" --custom_dataset.test_split \"test\" --custom_dataset.file \"web_scraper_dataset.py\"  --run_validation True --batching_strategy padding  --use_peft --peft_method lora\n",
    "#! CUDA_VISIBLE_DEVICES=1 torchrun --nnodes 1 --nproc_per_node 1  finetuning.py --enable_fsdp --lr 1e-5  --num_epochs 3 --batch_size_training 2 --model_name meta-llama/Llama-3.2-11B-Vision-Instruct --dist_checkpoint_root_folder ./finetuned_model --dist_checkpoint_folder fine-tuned  --use_fast_kernels --dataset \"custom_dataset\" --custom_dataset.test_split \"test\" --custom_dataset.file \"ocrvqa_dataset.py\"  --run_validation True --batching_strategy padding  --use_peft --peft_method lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c893ede7-3fbf-40e0-9c96-3d6602848d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['images', 'texts'],\n",
      "        num_rows: 15937\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['images', 'texts'],\n",
      "        num_rows: 165746\n",
      "    })\n",
      "})\n",
      "\n",
      "{'train': ['images', 'texts']}\n",
      "{'train': ['images', 'texts']}\n",
      "\n",
      "My dataset first sample:\n",
      "{ 'images': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1280x720 at 0x7F5AC8207AD0>,\n",
      "  'texts': [ { 'assistant': '[79.92, 7.64, 85.31, 10.42]',\n",
      "               'source': 'web_scraper',\n",
      "               'user': 'Return the bounding box of the Text link with the '\n",
      "                       \"words 'About Us'. It's used to navigate to the About \"\n",
      "                       'Us section of the website and if we click it the About '\n",
      "                       'Us section will load.'}]}\n",
      "\n",
      "Reference dataset first sample:\n",
      "{ 'images': [ <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=380x500 at 0x7F5AC82654D0>],\n",
      "  'texts': [ { 'assistant': 'David MACAULAY.',\n",
      "               'source': 'ocrvqa',\n",
      "               'user': 'Who wrote this book?\\nMake the answer very short.'},\n",
      "             { 'assistant': 'Underground.',\n",
      "               'source': 'ocrvqa',\n",
      "               'user': 'What is the title of this book?\\n'\n",
      "                       'Your answer should be very brief.'},\n",
      "             { 'assistant': \"Children's Books.\",\n",
      "               'source': 'ocrvqa',\n",
      "               'user': 'What type of book is this?\\n'\n",
      "                       'Your answer should be compact.'},\n",
      "             { 'assistant': 'Yes.',\n",
      "               'source': 'ocrvqa',\n",
      "               'user': \"Is this book related to Children's Books?\\n\"\n",
      "                       'Keep it short and to the point.'},\n",
      "             { 'assistant': 'No.',\n",
      "               'source': 'ocrvqa',\n",
      "               'user': 'Is this book related to History?\\n'\n",
      "                       'Your answer should be very brief.'}]}\n",
      "\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1280x720 at 0x7F5AC8287390>\n",
      "[<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=380x500 at 0x7F5AC8265010>]\n",
      "<class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Load the original dataset\n",
    "my_dataset = load_dataset(\"jwaters8978/web_scraper_dataset\")\n",
    "reference_dataset = load_dataset(\"HuggingFaceM4/the_cauldron\", name=\"ocrvqa\")\n",
    "\n",
    "print(my_dataset)\n",
    "print(reference_dataset)\n",
    "print()\n",
    "\n",
    "print(my_dataset.column_names)\n",
    "print(reference_dataset.column_names)\n",
    "print()\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "print(\"My dataset first sample:\")\n",
    "pp.pprint(my_dataset['train'][0])\n",
    "print(\"\\nReference dataset first sample:\")\n",
    "pp.pprint(reference_dataset['train'][0])\n",
    "print()\n",
    "\n",
    "print(my_dataset['train'][0]['images'])\n",
    "print(reference_dataset['train'][0]['images'])\n",
    "\n",
    "print(type(my_dataset['train'][0]['images']))\n",
    "print(type(reference_dataset['train'][0]['images']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "856b7b26-a87e-4ed7-ba42-56e8f4b3eb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Starting image-to-text generation...\n",
      "Using model: meta-llama/Llama-3.2-11B-Vision-Instruct\n",
      "Using PEFT/LoRA from: PATH/to/save/PEFT/model/\n",
      "Loading model and processor...\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:03<00:00,  1.35it/s]\n",
      "Loading PEFT model from PATH/to/save/PEFT/model/\n",
      "Processing image...\n",
      "Successfully loaded image from kitty-cat.jpg\n",
      "Generating text from image...\n",
      "Generating response...\n",
      "\n",
      "Generated Text:\n",
      "--------------------------------------------------\n",
      "end_header_id|>\n",
      "\n",
      "To find the bounding box for the kitten's face, we can use the following steps:\n",
      "\n",
      "1. Identify the kitten's face: The kitten's face is the area that includes its eyes, nose, mouth, and ears.\n",
      "\n",
      "2. Determine the coordinates of the top-left corner of the face: The top-left corner of the face is located at (0, 0).\n",
      "\n",
      "3. Determine the coordinates of the bottom-right corner of the face: The bottom-right corner of the face is located at (0.59, 0.72).\n",
      "\n",
      "4. Calculate the width and height of the bounding box: The width of the bounding box is the difference between the x-coordinates of the top-left and bottom-right corners, which is 0.59 - 0.00 = 0.59. The height of the bounding box is the difference between the y-coordinates of the top-left and bottom-right corners, which is 0.72 - 0.00 = 0.72.\n",
      "\n",
      "5. Calculate the center of the bounding box: The center of the bounding box is located at (0.295, 0.36).\n",
      "\n",
      "6. Calculate the size of the bounding box: The size of the bounding box is 0.59 x 0.72.\n",
      "\n",
      "Therefore, the bounding box for the kitten's face is (0, 0, 0.59, 0.72).<|eot_id|>\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#!python inference.py --model_name meta-llama/Llama-3.2-11B-Vision-Instruct --prompt_file prompt.txt --peft_model PATH/to/save/PEFT/model/ --use_auditnlg\n",
    "#!wget --header=\"User-Agent: Mozilla/5.0\" https://images.pexels.com/photos/45201/kitty-cat-kitten-pet-45201.jpeg -O kitty-cat.jpg\n",
    "\n",
    "!python multi_modal_infer.py --image_path kitty-cat.jpg --prompt_text \"What is the bounding box for the kittens face?\" --temperature 0.5 --top_p 0.8 --model_name \"meta-llama/Llama-3.2-11B-Vision-Instruct\" --peft_model_path \"PATH/to/save/PEFT/model/\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
